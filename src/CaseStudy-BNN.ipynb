{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Case Study 5: Bayesian Neural Network\n",
        "\n",
        "Adapted from https://num.pyro.ai/en/stable/examples/bnn.html , we first see the NumPyro implementation and then SOGA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sogaPreprocessor import *\n",
        "from producecfg import *\n",
        "from libSOGA import *\n",
        "from time import time\n",
        "\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sample: 100%|██████████| 3000/3000 [00:04<00:00, 678.96it/s, 15 steps of size 2.31e-01. acc. prob=0.85] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
            "  prec_obs      0.98      0.38      0.94      0.37      1.55    970.20      1.00\n",
            "   w1[0,0]     -0.11      0.97     -0.13     -1.70      1.49   1633.86      1.00\n",
            "   w1[0,1]     -0.21      0.96     -0.21     -1.74      1.42   1637.72      1.00\n",
            "   w1[1,0]     -0.00      0.96      0.00     -1.54      1.56   2012.00      1.00\n",
            "   w1[1,1]      0.00      0.92      0.01     -1.51      1.50   1611.33      1.00\n",
            "   w2[0,0]     -0.12      0.99     -0.11     -1.76      1.46   1629.87      1.00\n",
            "   w2[0,1]     -0.18      0.94     -0.17     -1.90      1.18   1679.31      1.00\n",
            "   w2[1,0]     -0.10      0.93     -0.10     -1.66      1.39   2034.71      1.00\n",
            "   w2[1,1]     -0.16      1.01     -0.16     -1.81      1.59   1460.40      1.00\n",
            "   w3[0,0]     -0.08      0.89     -0.07     -1.59      1.30   1669.51      1.00\n",
            "   w3[1,0]     -0.06      0.95     -0.06     -1.58      1.57   1544.18      1.00\n",
            "\n",
            "Number of divergences: 6\n",
            "\n",
            "MCMC elapsed time: 8.268379211425781\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import jax\n",
        "from jax import vmap\n",
        "import jax.numpy as jnp\n",
        "import jax.random as random\n",
        "\n",
        "import numpyro\n",
        "from numpyro import handlers\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS\n",
        "\n",
        "matplotlib.use(\"Agg\")  # noqa: E402\n",
        "\n",
        "\n",
        "# the non-linearity we use in our neural network\n",
        "def nonlin(x):\n",
        "    return jax.nn.relu(x)\n",
        "\n",
        "\n",
        "# a two-layer bayesian neural network with computational flow\n",
        "# given by D_X => D_H => D_H => D_Y where D_H is the number of\n",
        "# hidden units. (note we indicate tensor dimensions in the comments)\n",
        "def model(X, Y, D_H, D_Y=1):\n",
        "    N, D_X = X.shape\n",
        "\n",
        "    # sample first layer (we put unit normal priors on all weights)\n",
        "    w1 = numpyro.sample(\"w1\", dist.Normal(jnp.zeros((D_X, D_H)), jnp.ones((D_X, D_H))))\n",
        "    assert w1.shape == (D_X, D_H)\n",
        "    z1 = nonlin(jnp.matmul(X, w1))  # <= first layer of activations\n",
        "    assert z1.shape == (N, D_H)\n",
        "\n",
        "    # sample second layer\n",
        "    w2 = numpyro.sample(\"w2\", dist.Normal(jnp.zeros((D_H, D_H)), jnp.ones((D_H, D_H))))\n",
        "    assert w2.shape == (D_H, D_H)\n",
        "    z2 = nonlin(jnp.matmul(z1, w2))  # <= second layer of activations\n",
        "    assert z2.shape == (N, D_H)\n",
        "\n",
        "    # sample final layer of weights and neural network output\n",
        "    w3 = numpyro.sample(\"w3\", dist.Normal(jnp.zeros((D_H, D_Y)), jnp.ones((D_H, D_Y))))\n",
        "    assert w3.shape == (D_H, D_Y)\n",
        "    z3 = jnp.matmul(z2, w3)  # <= output of the neural network\n",
        "    assert z3.shape == (N, D_Y)\n",
        "\n",
        "    if Y is not None:\n",
        "        assert z3.shape == Y.shape\n",
        "\n",
        "    # we put a prior on the observation noise\n",
        "    prec_obs = numpyro.sample(\"prec_obs\", dist.Normal(0., 1.0))  #Originally Gamma(3.0, 1.0)\n",
        "    sigma_obs = 1.0 / jnp.sqrt(prec_obs)\n",
        "\n",
        "    # observe data\n",
        "    with numpyro.plate(\"data\", N):\n",
        "        # note we use to_event(1) because each observation has shape (1,)\n",
        "        numpyro.sample(\"Y\", dist.Normal(z3, sigma_obs).to_event(1), obs=Y)\n",
        "\n",
        "\n",
        "# helper function for HMC inference\n",
        "def run_inference(model, rng_key, X, Y, D_H):\n",
        "    start = time.time()\n",
        "    kernel = NUTS(model)\n",
        "    mcmc = MCMC(\n",
        "        kernel,\n",
        "        num_warmup=1000,\n",
        "        num_samples=2000,\n",
        "        num_chains=1,\n",
        "        progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True,\n",
        "    )\n",
        "    mcmc.run(rng_key, X, Y, D_H)\n",
        "    mcmc.print_summary()\n",
        "    print(\"\\nMCMC elapsed time:\", time.time() - start)\n",
        "    return mcmc.get_samples()\n",
        "\n",
        "\n",
        "# helper function for prediction\n",
        "def predict(model, rng_key, samples, X, D_H):\n",
        "    model = handlers.substitute(handlers.seed(model, rng_key), samples)\n",
        "    # note that Y will be sampled in the model because we pass Y=None here\n",
        "    model_trace = handlers.trace(model).get_trace(X=X, Y=None, D_H=D_H)\n",
        "    return model_trace[\"Y\"][\"value\"]\n",
        "\n",
        "\n",
        "# create artificial regression dataset\n",
        "def get_data(N=20, D_X=3, sigma_obs=0.05, N_test=500):\n",
        "    D_Y = 1  # create 1d outputs\n",
        "    np.random.seed(0)\n",
        "    X = jnp.linspace(-1, 1, N)\n",
        "    X = jnp.power(X[:, np.newaxis], jnp.arange(D_X))\n",
        "    W = 0.5 * np.random.randn(D_X)\n",
        "    Y = jnp.dot(X, W) + 0.5 * jnp.power(0.5 + X[:, 1], 2.0) * jnp.sin(4.0 * X[:, 1])\n",
        "    Y += sigma_obs * np.random.randn(N)\n",
        "    Y = Y[:, np.newaxis]\n",
        "    Y -= jnp.mean(Y)\n",
        "    Y /= jnp.std(Y)\n",
        "\n",
        "    assert X.shape == (N, D_X)\n",
        "    assert Y.shape == (N, D_Y)\n",
        "\n",
        "    X_test = jnp.linspace(-1.3, 1.3, N_test)\n",
        "    X_test = jnp.power(X_test[:, np.newaxis], jnp.arange(D_X))\n",
        "\n",
        "    return X, Y, X_test\n",
        "\n",
        "\n",
        "args = [10, 2, 2]\n",
        "N, D_X, D_H = args\n",
        "X, Y, X_test = get_data(N=N, D_X=D_X)\n",
        "\n",
        "# do inference\n",
        "rng_key, rng_key_predict = random.split(random.PRNGKey(0))\n",
        "samples = run_inference(model, rng_key, X, Y, D_H)\n",
        "\n",
        "# predict Y_test at inputs X_test\n",
        "vmap_args = (\n",
        "    samples,\n",
        "    random.split(rng_key_predict, 2000 * 1),\n",
        ")\n",
        "predictions = vmap(\n",
        "    lambda samples, rng_key: predict(model, rng_key, samples, X_test, D_H)\n",
        ")(*vmap_args)\n",
        "predictions = predictions[..., 0]\n",
        "\n",
        "# compute mean prediction and confidence interval around median\n",
        "mean_prediction = jnp.mean(predictions, axis=0)\n",
        "percentiles = np.percentile(predictions, [5.0, 95.0], axis=0)\n",
        "\n",
        "# make plots\n",
        "fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
        "\n",
        "# plot training data\n",
        "ax.plot(X[:, 1], Y[:, 0], \"kx\")\n",
        "# plot 90% confidence level of predictions\n",
        "ax.fill_between(\n",
        "    X_test[:, 1], percentiles[0, :], percentiles[1, :], color=\"lightblue\"\n",
        ")\n",
        "# plot mean prediction\n",
        "ax.plot(X_test[:, 1], mean_prediction, \"blue\", ls=\"solid\", lw=2.0)\n",
        "ax.set(xlabel=\"X\", ylabel=\"Y\", title=\"Mean predictions with 90% CI\")\n",
        "\n",
        "plt.savefig(\"bnn_plot.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.0, -0.7777777910232544, -0.5555555820465088, -0.333333283662796, -0.11111113429069519, 0.11111116409301758, 0.3333333730697632, 0.5555555820465088, 0.7777777910232544, 1.0]\n",
            "(10,)\n"
          ]
        }
      ],
      "source": [
        "print((X[:,1]).tolist())\n",
        "print(X[:,1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize(params_dict, loss_function, y, cfg, steps=500):\n",
        "    optimizer = torch.optim.Adam([params_dict[key] for key in params_dict.keys()], lr=0.01)\n",
        "\n",
        "    total_start = time.time()\n",
        "\n",
        "    for i in range(steps):\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        \n",
        "        # loss\n",
        "        current_dist = start_SOGA(cfg, params_dict, pruning='ranking')\n",
        "\n",
        "        loss = loss_function(y, current_dist)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward(retain_graph=True)\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        # Print progress\n",
        "        if i % 1 == 0:\n",
        "            out = ''\n",
        "            for key in params_dict.keys():\n",
        "                out = out + key + ': ' + str(params_dict[key].item()) + ' '\n",
        "            out = out + f\" loss: {loss.item()}\"\n",
        "            print(out)\n",
        "\n",
        "    total_end = time.time()\n",
        "\n",
        "    print('Optimization performed in ', round(total_end-total_start, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_squared_error(y_true, dist):\n",
        "    return torch.mean((y_true - dist.gm.mean()) ** 2)\n",
        "\n",
        "def mean_squared_error_bayes(y_true, dist):\n",
        "    #This works for the means but of course not for the variances\n",
        "    return torch.mean((y_true - dist.gm.mean()[:-2]) ** 2)\n",
        "\n",
        "def neg_log_likelihood(y_true, dist):\n",
        "    #Calculate the log-likelihood of the data given the distribution\n",
        "    neg_log_likelihood = 0\n",
        "    for i in range(10):\n",
        "        neg_log_likelihood -= torch.log(dist.gm.marg_pdf(y_true[i].unsqueeze(0), i))\n",
        "    return neg_log_likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.0, -0.7777777910232544, -0.5555555820465088, -0.333333283662796, -0.11111113429069519, 0.11111116409301758, 0.3333333730697632, 0.5555555820465088, 0.7777777910232544, 1.0]\n",
            "(10,)\n"
          ]
        }
      ],
      "source": [
        "print((X[:,1]).tolist())\n",
        "print(X[:,1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 1])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert JAX array to NumPy array\n",
        "numpy_array = Y.__array__().copy()\n",
        "\n",
        "# Convert NumPy array to PyTorch tensor\n",
        "Ytorch = torch.from_numpy(numpy_array)\n",
        "Ytorch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3339],\n",
              "        [-0.2940],\n",
              "        [-0.2069],\n",
              "        [-0.5793],\n",
              "        [-0.1670],\n",
              "        [ 0.1788],\n",
              "        [ 1.2079],\n",
              "        [ 1.8025],\n",
              "        [ 0.4927],\n",
              "        [-2.1008]], dtype=torch.float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Ytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mu100: 0.009999999866369806 sigma100: 0.990000000230016 mu101: -0.009998953196849708 sigma101: 0.990000005198233 mu110: -0.009999999894822729 sigma110: 0.9900000001408742 mu111: 0.009999906923708831 sigma111: 1.009999994801767 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.009999881307914446 sigma300: 0.9900000000873542 mu310: 0.009999997675319882 sigma310: 0.9900000000422919  loss: 15.058224666171014\n",
            "mu100: 0.019993934463126223 sigma100: 0.9800003256727742 mu101: -0.018336183347813017 sigma101: 0.9800161574420118 mu110: -0.019984767893382622 sigma110: 0.9800139698213848 mu111: 0.019622946892534743 sigma111: 1.0199749605541948 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.01826063201058528 sigma300: 0.9800133700020317 mu310: 0.017459741682736948 sigma310: 0.9800062783560246  loss: 14.994924058856814\n",
            "mu100: 0.029977460021501437 sigma100: 0.9700018601017881 mu101: -0.026992782658149833 sigma101: 0.9700501781592545 mu110: -0.02994204747052795 sigma110: 0.9700529030485969 mu111: 0.029395249567140812 sigma111: 1.0299180152721306 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.027071653870397387 sigma300: 0.9700502495114293 mu310: 0.01938434969414084 sigma310: 0.9700239209422964  loss: 14.933794437974724\n",
            "mu100: 0.039945618787662784 sigma100: 0.9600047253611329 mu101: -0.03615732158297329 sigma101: 0.9601209577956611 mu110: -0.039860201772988726 sigma110: 0.9601295421692811 mu111: 0.03928361178554 sigma111: 1.0398036853257717 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.03541604364263444 sigma300: 0.9601214079187751 mu310: 0.018804117952353896 sigma310: 0.9600593287205684  loss: 14.875206503495352\n",
            "mu100: 0.04989377017966941 sigma100: 0.9500098474015569 mu101: -0.04560094665977092 sigma101: 0.9502437530978717 mu110: -0.049725674485063195 sigma110: 0.950258332241713 mu111: 0.04925375253417568 sigma111: 1.0496102472180109 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.037834983197511884 sigma300: 0.9502389973690761 mu310: 0.018474728743693908 sigma310: 0.950119510188011  loss: 14.818603207867488\n",
            "mu100: 0.059816086904844606 sigma100: 0.9400199883130423 mu101: -0.055244055702530284 sigma101: 0.9404364463685367 mu110: -0.059521647859738826 sigma110: 0.9404572130214738 mu111: 0.0592764485314772 sigma111: 1.0593124297386844 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.03646776051641014 sigma300: 0.9404176838023609 mu310: 0.018929232909698758 sigma310: 0.9402126275099865  loss: 14.763008402502793\n",
            "mu100: 0.06970621132371474 sigma100: 0.9300370550607868 mu101: -0.06489957879534557 sigma101: 0.930750661018432 mu110: -0.06923174715042367 sigma110: 0.9307467015093669 mu111: 0.06932554511568517 sigma111: 1.068847096092062 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.03404575592100613 sigma300: 0.9306725773844292 mu310: 0.01930512970335811 sigma310: 0.9303486708405273  loss: 14.710336754923953\n",
            "mu100: 0.07955862502550946 sigma100: 0.9200627081680801 mu101: -0.07450723008723568 sigma101: 0.9211947553053725 mu110: -0.07883850339732623 sigma110: 0.9211476279185511 mu111: 0.07947627171968576 sigma111: 1.0782013800935895 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.032490161319683054 sigma300: 0.9210183928042859 mu310: 0.01872256983792069 sigma310: 0.9205383393450409  loss: 14.661212165368145\n",
            "mu100: 0.08936772076192859 sigma100: 0.9100988477439858 mu101: -0.08401529970597392 sigma101: 0.9117795013480465 mu110: -0.08832335841335487 sigma110: 0.9116835470074207 mu111: 0.08971663243858236 sigma111: 1.0873606009315047 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.03257238489071408 sigma300: 0.9114711251579745 mu310: 0.017222304233415343 sigma310: 0.9107938231764849  loss: 14.614736960920215\n",
            "mu100: 0.09912753030752255 sigma100: 0.9001475683710306 mu101: -0.09374287888813161 sigma101: 0.9024868866047325 mu110: -0.0976665610373273 sigma110: 0.9023803567849725 mu111: 0.10001266339263067 sigma111: 1.0963369556122224 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.03387819344961904 sigma300: 0.9020476300040089 mu310: 0.015705128964980705 sigma310: 0.9011289865428743  loss: 14.57111200892749\n",
            "mu100: 0.10883257389196357 sigma100: 0.8902111023414917 mu101: -0.1035967243419804 sigma101: 0.8933341116470473 mu110: -0.1068475035355871 sigma110: 0.8932675341537685 mu111: 0.11033557715862544 sigma111: 1.1051110250796177 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.035713201613270296 sigma300: 0.8927661869080088 mu310: 0.01526021330958161 sigma310: 0.8915593388531727  loss: 14.530121524282258\n",
            "mu100: 0.11847764823877494 sigma100: 0.8802917542371991 mu101: -0.11353142900509237 sigma101: 0.8843400356496751 mu110: -0.11584442445674276 sigma110: 0.8843780216903576 mu111: 0.12071219661075924 sigma111: 1.1136589027898534 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.03792289481954394 sigma300: 0.8836460900803175 mu310: 0.016224447762184162 sigma310: 0.8821022176450335  loss: 14.491939736134393\n",
            "mu100: 0.12805721158563152 sigma100: 0.870392283044609 mu101: -0.12346518103823627 sigma101: 0.8755186846736351 mu110: -0.12463442522260287 sigma110: 0.8757478840913038 mu111: 0.13110560947446495 sigma111: 1.1219664923559365 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.04098586258393644 sigma300: 0.8747074722173924 mu310: 0.018077770876723655 sigma310: 0.872776880486121  loss: 14.456599216362434\n",
            "mu100: 0.1375658837823473 sigma100: 0.8605155989814459 mu101: -0.13332460353105027 sigma101: 0.8668825859669508 mu110: -0.1331937717264738 sigma110: 0.8674163712945064 mu111: 0.1414816445939845 sigma111: 1.1300220568796298 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.04539112040199931 sigma300: 0.8659711709026108 mu310: 0.019998456980822855 sigma310: 0.8636045734366196  loss: 14.424112298758313\n",
            "mu100: 0.14699857939299035 sigma100: 0.8506646733471032 mu101: -0.14304381766344232 sigma101: 0.8584425377594586 mu110: -0.14149831636250865 sigma110: 0.8594254597991677 mu111: 0.1518090819173985 sigma111: 1.137816408438458 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.051141358752789086 sigma300: 0.8574585187088668 mu310: 0.021381693838238448 sigma310: 0.8546085701722883  loss: 14.394468389554351\n",
            "mu100: 0.15635060132845757 sigma100: 0.840842485358516 mu101: -0.1525638569179609 sigma101: 0.8502074481145647 mu110: -0.14952395270355234 sigma110: 0.8518191633938741 mu111: 0.16205963333002207 sigma111: 1.1453429768401058 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.05794515145509299 sigma300: 0.849191098726885 mu310: 0.022248471839507487 sigma310: 0.8458141533274522  loss: 14.36761645556598\n",
            "mu100: 0.16561769287555708 sigma100: 0.8310520095133711 mu101: -0.16183234713344777 sigma101: 0.8421842285225488 mu110: -0.15724695777872394 sigma110: 0.8446428241591165 mu111: 0.17220788916412322 sigma111: 1.15259778974997 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.06548043767675564 sigma300: 0.8411905110028297 mu310: 0.023148827405459992 sigma310: 0.8372485063901521  loss: 14.343489292718747\n",
            "mu100: 0.1747960522681493 sigma100: 0.8212962290936745 mu101: -0.1708033017929292 sigma101: 0.8343777371360782 mu110: -0.16464414190007634 sigma110: 0.8379425249144177 mu111: 0.18223126160337713 sigma111: 1.1595793846686295 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.07351217551876986 sigma300: 0.8334781486383999 mu310: 0.024673903869813628 sigma310: 0.8289404724385127  loss: 14.322001212118336\n",
            "mu100: 0.18388232458233633 sigma100: 0.8115781519726976 mu101: -0.17943694110135341 sigma101: 0.8267907858513381 mu110: -0.17169289038575422 sigma110: 0.8317645190468365 mu111: 0.19210992242520164 sigma111: 1.166288653128014 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.08198259301426658 sigma300: 0.826074951846497 mu310: 0.026974540344789008 sigma310: 0.8209201572498862  loss: 14.30302117588887\n",
            "mu100: 0.19287373159441729 sigma100: 0.8019004426271448 mu101: -0.18775849139444073 sigma101: 0.8194235696085942 mu110: -0.1783711372470975 sigma110: 0.8261543339362337 mu111: 0.20182891552192642 sigma111: 1.1727281798694846 mu200: 0.0 sigma200: 1.0 mu201: 0.0 sigma201: 1.0 mu210: 0.0 sigma210: 1.0 mu211: 0.0 sigma211: 1.0 mu300: -0.090990120142382 sigma300: 0.8190007723212842 mu310: 0.029717465744207295 sigma310: 0.8132184570869724  loss: 14.286459232469284\n",
            "Optimization performed in  43.65\n"
          ]
        }
      ],
      "source": [
        "compiledFile=compile2SOGA('../programs/SOGA/Optimization/Case Studies/bnn3.soga')\n",
        "cfg = produce_cfg(compiledFile)\n",
        "\n",
        "pars = {'mu100':0., 'sigma100':1., 'mu101':0., 'sigma101':1.,'mu110':0., 'sigma110':1.,'mu111':0., 'sigma111':1.,'mu200':0., 'sigma200':1.,\n",
        "        'mu201':0., 'sigma201':1.,'mu210':0., 'sigma210':1.,'mu211':0., 'sigma211':1.,'mu300':0., 'sigma300':1.,'mu310':0., 'sigma310':1.,}\n",
        "\n",
        "\n",
        "#pars = {'mu100':0., 'sigma100':1., 'mu101':0., 'sigma101':1.,'mu110':0., 'sigma110':1.,'mu111':0., 'sigma111':1.,'mu300':0., 'sigma300':1.,'mu310':0., 'sigma310':1.}\n",
        "#pars = {}\n",
        "\n",
        "for key, value in pars.items():\n",
        "    pars[key] = torch.tensor(value, requires_grad=True)    \n",
        "\n",
        "output_dist = start_SOGA(cfg, pars, pruning='ranking') #params_dict \n",
        "\n",
        "optimize(pars, neg_log_likelihood, Ytorch, cfg, steps=20)\n",
        "\n",
        "#predictive mean\n",
        "#y_pred = params_dict['muw'].detach().numpy()*X.detach().numpy()+params_dict['mub'].detach().numpy()\n",
        "\n",
        "#predictive variance\n",
        "#sigma_y_pred = np.sqrt(params_dict['sigmay'].detach().numpy()**2 + (X.detach().numpy()*params_dict['sigmaw'].detach().numpy())**2 + params_dict['sigmab'].detach().numpy()**2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dist = start_SOGA(cfg, pars, pruning='ranking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0003, -0.0004,  0.0003,  0.0013,  0.0022,  0.0030,  0.0037,  0.0041,\n",
              "         0.0043,  0.0043], grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dist.gm.mean()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3339],\n",
              "        [-0.2940],\n",
              "        [-0.2069],\n",
              "        [-0.5793],\n",
              "        [-0.1670],\n",
              "        [ 0.1788],\n",
              "        [ 1.2079],\n",
              "        [ 1.8025],\n",
              "        [ 0.4927],\n",
              "        [-2.1008]], dtype=torch.float32)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Ytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
